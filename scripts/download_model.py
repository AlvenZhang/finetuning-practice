#!/usr/bin/env python3
"""
æ¨¡å‹ä¸‹è½½è„šæœ¬
Download base model for fine-tuning
"""

import os
import sys
import argparse
from pathlib import Path
import yaml
import logging
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from transformers import AutoModelForCausalLM, AutoTokenizer
from src.utils.logging import setup_logging

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹")

    parser.add_argument(
        "--model_name",
        type=str,
        default="Qwen/Qwen2.5-3B-Instruct",
        help="æ¨¡å‹åç§°"
    )

    parser.add_argument(
        "--output_dir",
        type=str,
        default="models/base",
        help="æ¨¡å‹ä¿å­˜ç›®å½•"
    )

    parser.add_argument(
        "--config_file",
        type=str,
        default="config/model_config_qwen.yaml",
        help="æ¨¡å‹é…ç½®æ–‡ä»¶"
    )

    parser.add_argument(
        "--token",
        type=str,
        default=None,
        help="Hugging Faceè®¿é—®token"
    )

    parser.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°ä¸‹è½½"
    )

    parser.add_argument(
        "--tokenizer_only",
        action="store_true",
        help="ä»…ä¸‹è½½åˆ†è¯å™¨"
    )

    parser.add_argument(
        "--model_only",
        action="store_true",
        help="ä»…ä¸‹è½½æ¨¡å‹"
    )

    return parser.parse_args()

def load_config(config_file: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        logging.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return {}
    except Exception as e:
        logging.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return {}

def check_model_access(model_name: str, token: Optional[str] = None) -> bool:
    """æ£€æŸ¥æ¨¡å‹è®¿é—®æƒé™"""
    try:
        from huggingface_hub import HfApi

        api = HfApi(token=token)
        repo_info = api.repo_info(model_name)

        # æ£€æŸ¥æ˜¯å¦ä¸ºç§æœ‰ä»“åº“
        if hasattr(repo_info, 'private') and repo_info.private:
            if not token:
                print(f"âŒ æ¨¡å‹ {model_name} éœ€è¦è®¿é—®token")
                print("è¯·ä½¿ç”¨ --token å‚æ•°æˆ–è¿è¡Œ huggingface-cli login")
                return False

        return True

    except Exception as e:
        logging.warning(f"æ£€æŸ¥æ¨¡å‹è®¿é—®æƒé™æ—¶å‡ºé”™: {e}")
        return True  # å‡è®¾å¯ä»¥è®¿é—®ï¼Œè®©ä¸‹è½½è¿‡ç¨‹è‡ªå·±å¤„ç†é”™è¯¯

def download_tokenizer(
    model_name: str,
    output_dir: Path,
    token: Optional[str] = None,
    force: bool = False
) -> bool:
    """ä¸‹è½½åˆ†è¯å™¨"""
    tokenizer_dir = output_dir / "tokenizer"

    if tokenizer_dir.exists() and not force:
        print(f"âœ… åˆ†è¯å™¨å·²å­˜åœ¨: {tokenizer_dir}")
        return True

    try:
        print(f"ğŸ“¥ ä¸‹è½½åˆ†è¯å™¨: {model_name}")

        tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            token=token,
            trust_remote_code=True
        )

        # ä¿å­˜åˆ†è¯å™¨
        tokenizer_dir.mkdir(parents=True, exist_ok=True)
        tokenizer.save_pretrained(tokenizer_dir)

        print(f"âœ… åˆ†è¯å™¨ä¸‹è½½å®Œæˆ: {tokenizer_dir}")
        print(f"   è¯æ±‡è¡¨å¤§å°: {len(tokenizer)}")

        return True

    except Exception as e:
        print(f"âŒ åˆ†è¯å™¨ä¸‹è½½å¤±è´¥: {e}")
        logging.error(f"åˆ†è¯å™¨ä¸‹è½½å¤±è´¥: {e}", exc_info=True)
        return False

def download_model(
    model_name: str,
    output_dir: Path,
    token: Optional[str] = None,
    force: bool = False
) -> bool:
    """ä¸‹è½½æ¨¡å‹"""
    model_dir = output_dir / "model"

    if model_dir.exists() and not force:
        print(f"âœ… æ¨¡å‹å·²å­˜åœ¨: {model_dir}")
        return True

    try:
        print(f"ğŸ“¥ ä¸‹è½½æ¨¡å‹: {model_name}")
        print("âš ï¸  æ³¨æ„: æ¨¡å‹ä¸‹è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´...")

        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            token=token,
            trust_remote_code=True,
            torch_dtype="auto",  # è‡ªåŠ¨é€‰æ‹©æ•°æ®ç±»å‹
            low_cpu_mem_usage=True  # é™ä½å†…å­˜ä½¿ç”¨
        )

        # ä¿å­˜æ¨¡å‹
        model_dir.mkdir(parents=True, exist_ok=True)
        model.save_pretrained(model_dir)

        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in model.parameters())
        print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_dir}")
        print(f"   å‚æ•°æ•°é‡: {total_params:,}")
        print(f"   æ¨¡å‹å¤§å°: {total_params * 4 / (1024**3):.2f} GB (FP32)")

        return True

    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
        logging.error(f"æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}", exc_info=True)
        return False

def create_download_info(
    model_name: str,
    output_dir: Path,
    tokenizer_success: bool,
    model_success: bool
):
    """åˆ›å»ºä¸‹è½½ä¿¡æ¯æ–‡ä»¶"""
    from datetime import datetime

    download_info = {
        "model_name": model_name,
        "download_time": datetime.now().isoformat(),
        "tokenizer_downloaded": tokenizer_success,
        "model_downloaded": model_success,
        "output_directory": str(output_dir)
    }

    info_file = output_dir / "download_info.yaml"
    with open(info_file, 'w', encoding='utf-8') as f:
        yaml.dump(download_info, f, default_flow_style=False)

    print(f"ğŸ“‹ ä¸‹è½½ä¿¡æ¯å·²ä¿å­˜: {info_file}")

def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()

    # è®¾ç½®æ—¥å¿—
    setup_logging(level="INFO")
    logger = logging.getLogger(__name__)

    print("ğŸ¤– LLMæ¨¡å‹ä¸‹è½½å·¥å…·")
    print("=" * 50)

    # ä»é…ç½®æ–‡ä»¶è·å–æ¨¡å‹åç§°ï¼ˆå¦‚æœä½¿ç”¨é»˜è®¤å€¼ï¼‰
    if args.model_name == "Qwen/Qwen2.5-3B-Instruct":  # é»˜è®¤å€¼
        config = load_config(args.config_file)
        if config and 'model' in config and 'name' in config['model']:
            args.model_name = config['model']['name']

    print(f"ğŸ“¦ æ¨¡å‹: {args.model_name}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # æ£€æŸ¥è®¿é—®æƒé™
    if not check_model_access(args.model_name, args.token):
        return 1

    # ç¡®å®šä¸‹è½½å†…å®¹
    download_tokenizer_flag = not args.model_only
    download_model_flag = not args.tokenizer_only

    success_count = 0
    total_tasks = sum([download_tokenizer_flag, download_model_flag])

    tokenizer_success = True
    model_success = True

    try:
        # ä¸‹è½½åˆ†è¯å™¨
        if download_tokenizer_flag:
            print("\\n" + "="*30)
            print("ğŸ“ ä¸‹è½½åˆ†è¯å™¨")
            print("="*30)

            tokenizer_success = download_tokenizer(
                args.model_name,
                output_dir,
                args.token,
                args.force
            )

            if tokenizer_success:
                success_count += 1

        # ä¸‹è½½æ¨¡å‹
        if download_model_flag:
            print("\\n" + "="*30)
            print("ğŸ§  ä¸‹è½½æ¨¡å‹")
            print("="*30)

            model_success = download_model(
                args.model_name,
                output_dir,
                args.token,
                args.force
            )

            if model_success:
                success_count += 1

        # åˆ›å»ºä¸‹è½½ä¿¡æ¯
        create_download_info(
            args.model_name,
            output_dir,
            tokenizer_success,
            model_success
        )

        # æ€»ç»“
        print("\\n" + "="*50)
        if success_count == total_tasks:
            print("ğŸ‰ æ‰€æœ‰ä¸‹è½½ä»»åŠ¡å®Œæˆï¼")
            print(f"ğŸ“ æ–‡ä»¶ä½ç½®: {output_dir}")

            # æ˜¾ç¤ºç›®å½•ç»“æ„
            print("\\nğŸ“‚ ç›®å½•ç»“æ„:")
            for item in sorted(output_dir.rglob("*")):
                if item.is_file():
                    relative_path = item.relative_to(output_dir)
                    size_mb = item.stat().st_size / (1024 * 1024)
                    print(f"   {relative_path} ({size_mb:.1f} MB)")

            return 0
        else:
            print(f"âš ï¸  éƒ¨åˆ†ä»»åŠ¡å¤±è´¥: {success_count}/{total_tasks}")
            return 1

    except KeyboardInterrupt:
        print("\\nâ¸ï¸  ä¸‹è½½è¢«ç”¨æˆ·ä¸­æ–­")
        return 0

    except Exception as e:
        print(f"\\nâŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        logger.error(f"ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºé”™: {e}", exc_info=True)
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
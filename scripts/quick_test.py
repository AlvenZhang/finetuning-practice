#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•æœ¬åœ°æ¨¡å‹å’Œæ•°æ®
Quick test for local model and data
"""

import sys
from pathlib import Path
import json

def test_data():
    """æµ‹è¯•æ•°æ®æ–‡ä»¶"""
    print("=== æµ‹è¯•æ•°æ®æ–‡ä»¶ ===\n")

    data_path = Path("data/raw/alpaca_data_cleaned.json")

    if not data_path.exists():
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        return False

    try:
        with open(data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼")
        print(f"   æ ·æœ¬æ•°é‡: {len(data)}")
        print(f"   æ–‡ä»¶å¤§å°: {data_path.stat().st_size / 1024**2:.1f} MB")

        if len(data) > 0:
            sample = data[0]
            print(f"   æ ·æœ¬æ ¼å¼: {list(sample.keys())}")
            print(f"\n   ç¤ºä¾‹:")
            print(f"   æŒ‡ä»¤: {sample.get('instruction', 'N/A')[:80]}...")
            if 'input' in sample:
                inp = sample['input']
                print(f"   è¾“å…¥: {inp[:50] if inp else '(ç©º)'}...")
            print(f"   è¾“å‡º: {sample.get('output', 'N/A')[:80]}...")

        return True

    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False

def test_model_files():
    """æµ‹è¯•æ¨¡å‹æ–‡ä»¶"""
    print("\n=== æµ‹è¯•æ¨¡å‹æ–‡ä»¶ ===\n")

    model_path = Path("models")

    required_files = [
        "config.json",
        "tokenizer.json",
        "tokenizer_config.json",
        "model.safetensors.index.json"
    ]

    print(f"ğŸ“‚ æ£€æŸ¥æ¨¡å‹ç›®å½•: {model_path}")

    all_ok = True
    for file in required_files:
        file_path = model_path / file
        if file_path.exists():
            size = file_path.stat().st_size / 1024
            print(f"âœ… {file}: {size:.1f} KB")
        else:
            print(f"âŒ {file}: ä¸å­˜åœ¨")
            all_ok = False

    # æ£€æŸ¥æ¨¡å‹æƒé‡æ–‡ä»¶
    safetensors_files = list(model_path.glob("*.safetensors"))
    if safetensors_files:
        print(f"\nğŸ“¦ æ¨¡å‹æƒé‡æ–‡ä»¶:")
        total_size = 0
        for file in safetensors_files:
            size = file.stat().st_size / 1024**3
            total_size += size
            print(f"   {file.name}: {size:.2f} GB")
        print(f"   æ€»è®¡: {total_size:.2f} GB")

    return all_ok

def main():
    print("ğŸš€ å¿«é€Ÿæµ‹è¯•æœ¬åœ°ç¯å¢ƒ\n")

    # æµ‹è¯•æ•°æ®
    data_ok = test_data()

    # æµ‹è¯•æ¨¡å‹æ–‡ä»¶
    model_ok = test_model_files()

    # æ€»ç»“
    print("\n" + "="*60)
    print("\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"   {'âœ…' if data_ok else 'âŒ'} æ•°æ®æ–‡ä»¶")
    print(f"   {'âœ…' if model_ok else 'âŒ'} æ¨¡å‹æ–‡ä»¶")

    if data_ok and model_ok:
        print("\nğŸ‰ æ–‡ä»¶æ£€æŸ¥é€šè¿‡ï¼")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("   1. æµ‹è¯•GPUç¯å¢ƒ: python scripts/test_gpu_env.py")
        print("   2. å¼€å§‹è®­ç»ƒ: python scripts/train.py --model_config config/gpu_model_config.yaml --lora_config config/gpu_lora_config.yaml --device cuda")
        return 0
    else:
        print("\nâš ï¸  è¯·æ£€æŸ¥ä¸Šè¿°é—®é¢˜")
        return 1

if __name__ == "__main__":
    sys.exit(main())
